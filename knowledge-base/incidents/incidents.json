[
  {
    "incident_id": "INC-2024-001",
    "title": "Azure OpenAI API Rate Limit 초과",
    "severity": "high",
    "category": "api",
    "occurred_at": "2024-01-15T14:30:00Z",
    "resolved_at": "2024-01-15T15:00:00Z",
    "affected_systems": ["LLMService", "All Agents"],
    "description": "Azure OpenAI API 호출 시 429 Rate Limit Exceeded 오류가 지속적으로 발생하여 모든 Agent의 작업이 중단되었습니다.",
    "root_cause": "동시에 많은 Agent가 LLM을 호출하면서 Azure OpenAI의 분당 요청 제한(RPM)을 초과했습니다. 기본 RPM 설정이 60으로 낮게 설정되어 있었습니다.",
    "solution": "1. Azure Portal에서 Quota 증가 요청 (60 RPM → 300 RPM)\n2. LLMService에 Exponential Backoff Retry 로직 추가\n3. Redis 기반 Rate Limiter 구현\n4. 캐싱 메커니즘 도입하여 중복 요청 감소",
    "prevention": "1. 프로덕션 환경에서는 충분한 Quota 확보\n2. Rate Limiting 모니터링 알림 설정\n3. 우선순위 기반 요청 큐 구현",
    "tags": ["azure-openai", "rate-limit", "api"]
  },
  {
    "incident_id": "INC-2024-002",
    "title": "PostgreSQL 연결 풀 고갈",
    "severity": "critical",
    "category": "database",
    "occurred_at": "2024-01-20T09:15:00Z",
    "resolved_at": "2024-01-20T10:30:00Z",
    "affected_systems": ["Database", "API Server", "All Agents"],
    "description": "PostgreSQL 연결 풀이 고갈되어 새로운 데이터베이스 연결을 생성할 수 없어 API 요청이 실패했습니다.",
    "root_cause": "연결이 제대로 반환되지 않고 누적되어 최대 연결 수(max_connections=100)에 도달했습니다. Agent 실행 후 DB 연결을 명시적으로 닫지 않은 것이 원인입니다.",
    "solution": "1. 모든 유휴 연결 강제 종료\n2. max_connections를 200으로 증가\n3. Connection Pooling 설정 조정 (pool_size=20, max_overflow=10)\n4. 모든 DB 접근 코드에 context manager 패턴 적용\n5. Connection timeout 설정 (30초)",
    "prevention": "1. Database connection 모니터링 알림 설정\n2. 정기적인 Connection pool 통계 확인\n3. 코드 리뷰 시 Connection 관리 체크\n4. Connection leak detection 도구 도입",
    "tags": ["postgresql", "connection-pool", "database"]
  },
  {
    "incident_id": "INC-2024-003",
    "title": "Qdrant 메모리 초과로 인한 서비스 중단",
    "severity": "critical",
    "category": "vector-db",
    "occurred_at": "2024-01-25T16:45:00Z",
    "resolved_at": "2024-01-25T18:00:00Z",
    "affected_systems": ["Qdrant", "RAGService", "Knowledge Base"],
    "description": "Qdrant Vector Database가 메모리 부족으로 crash되어 RAG 기반 검색 기능이 완전히 중단되었습니다.",
    "root_cause": "대량의 문서(약 100,000개)를 한 번에 인덱싱하면서 메모리 사용량이 급증했습니다. Docker 컨테이너의 메모리 제한(4GB)을 초과했습니다.",
    "solution": "1. Qdrant 컨테이너 재시작\n2. Docker 메모리 제한을 8GB로 증가\n3. Scalar Quantization 활성화하여 메모리 사용량 50% 감소\n4. 배치 크기를 1000개에서 100개로 감소\n5. 인덱싱 스케줄을 분산 처리로 변경",
    "prevention": "1. Qdrant 메모리 사용량 모니터링 및 알림 설정\n2. 대용량 인덱싱 시 배치 처리 및 속도 제한 적용\n3. 정기적인 불필요한 문서 정리\n4. Production 환경에서는 최소 16GB 메모리 할당",
    "tags": ["qdrant", "memory", "vector-db", "oom"]
  },
  {
    "incident_id": "INC-2024-004",
    "title": "MCP ServiceNow 서버 인증 만료",
    "severity": "medium",
    "category": "integration",
    "occurred_at": "2024-02-01T08:00:00Z",
    "resolved_at": "2024-02-01T09:30:00Z",
    "affected_systems": ["MCPHub", "ITSAgent", "ServiceNow Integration"],
    "description": "ServiceNow MCP 서버가 401 Unauthorized 오류를 반환하여 ITS Agent가 티켓을 생성하지 못했습니다.",
    "root_cause": "ServiceNow API 인증 토큰이 만료되었습니다. 토큰 갱신 로직이 구현되지 않았고, 만료 알림도 없었습니다.",
    "solution": "1. ServiceNow에서 새로운 API 토큰 발급\n2. .env 파일의 SERVICENOW_PASSWORD 업데이트\n3. MCP ServiceNow 서버 재시작\n4. 토큰 자동 갱신 로직 추가\n5. 토큰 만료 7일 전 알림 설정",
    "prevention": "1. OAuth 2.0 기반 인증으로 마이그레이션\n2. 토큰 만료 일자 모니터링\n3. 자동 갱신 메커니즘 구현\n4. 인증 실패 시 즉시 알림",
    "tags": ["servicenow", "authentication", "mcp", "api"]
  },
  {
    "incident_id": "INC-2024-005",
    "title": "Agent Task Timeout 빈번 발생",
    "severity": "medium",
    "category": "performance",
    "occurred_at": "2024-02-05T11:20:00Z",
    "resolved_at": "2024-02-05T14:00:00Z",
    "affected_systems": ["ChangeManagementAgent", "Task Queue"],
    "description": "Change Management Agent가 복잡한 배포 작업 수행 시 30분 timeout에 걸려 작업이 실패했습니다.",
    "root_cause": "기본 timeout 설정이 30분(1800초)인데, 복잡한 배포 작업은 평균 45분이 소요되었습니다. 특히 여러 Agent를 순차적으로 호출하는 경우 더 오래 걸렸습니다.",
    "solution": "1. Task별 timeout 설정을 유연하게 변경 (30분 → 60분)\n2. Long-running task를 위한 별도 Queue 생성\n3. Task 진행 상태를 주기적으로 업데이트하여 timeout 방지\n4. 복잡한 작업을 여러 sub-task로 분할",
    "prevention": "1. Task 유형별 적절한 timeout 설정\n2. Timeout 발생 통계 모니터링\n3. 긴 작업은 비동기 처리 및 콜백 활용\n4. Task 실행 시간 예측 모델 개발",
    "tags": ["timeout", "performance", "task-queue"]
  },
  {
    "incident_id": "INC-2024-006",
    "title": "RAG 검색 정확도 저하",
    "severity": "low",
    "category": "ai",
    "occurred_at": "2024-02-10T13:00:00Z",
    "resolved_at": "2024-02-10T16:30:00Z",
    "affected_systems": ["RAGService", "BizSupportAgent"],
    "description": "사용자 질문에 대한 RAG 기반 답변의 정확도가 낮아져 부적절한 답변이 생성되었습니다.",
    "root_cause": "1. 지식 베이스에 오래된 문서와 최신 문서가 혼재되어 있음\n2. score_threshold가 0.7로 낮게 설정되어 관련성이 낮은 문서도 검색됨\n3. 문서 메타데이터(날짜, 버전 등)를 활용하지 않음",
    "solution": "1. score_threshold를 0.7에서 0.8로 상향 조정\n2. 1년 이상 된 문서에 'outdated' 태그 추가\n3. 검색 시 최신 문서 우선순위 부여\n4. Hybrid search 도입 (Vector + Keyword)\n5. 사용자 피드백 기반 재학습 파이프라인 구축",
    "prevention": "1. 정기적인 지식 베이스 업데이트 및 검증\n2. 문서 버전 관리 체계 수립\n3. RAG 답변 품질 모니터링 및 평가\n4. A/B 테스트를 통한 파라미터 최적화",
    "tags": ["rag", "search-quality", "knowledge-base"]
  },
  {
    "incident_id": "INC-2024-007",
    "title": "Redis Cache 동기화 문제",
    "severity": "medium",
    "category": "cache",
    "occurred_at": "2024-02-15T10:00:00Z",
    "resolved_at": "2024-02-15T11:00:00Z",
    "affected_systems": ["Redis", "API Server", "Cache Layer"],
    "description": "데이터베이스의 데이터가 업데이트되었으나 Redis 캐시가 무효화되지 않아 오래된 데이터가 반환되었습니다.",
    "root_cause": "캐시 무효화 로직이 일부 업데이트 경로에서 누락되었습니다. 특히 직접 DB를 수정하는 경우 캐시 무효화가 트리거되지 않았습니다.",
    "solution": "1. 영향받은 캐시 키 수동 삭제\n2. 모든 DB 업데이트 경로에 캐시 무효화 추가\n3. Cache-aside 패턴을 Write-through 패턴으로 변경\n4. TTL을 24시간에서 1시간으로 단축\n5. 캐시 버전 관리 도입",
    "prevention": "1. DB 트리거를 통한 자동 캐시 무효화\n2. 캐시 일관성 모니터링\n3. 정기적인 캐시 데이터 검증\n4. Cache warming 전략 수립",
    "tags": ["redis", "cache", "synchronization"]
  },
  {
    "incident_id": "INC-2024-008",
    "title": "Prometheus 메트릭 수집 중단",
    "severity": "low",
    "category": "monitoring",
    "occurred_at": "2024-02-20T07:30:00Z",
    "resolved_at": "2024-02-20T08:00:00Z",
    "affected_systems": ["Prometheus", "Grafana", "Monitoring"],
    "description": "Prometheus가 API 서버의 메트릭을 수집하지 못해 Grafana 대시보드에 데이터가 표시되지 않았습니다.",
    "root_cause": "API 서버의 /metrics 엔드포인트가 인증을 요구하도록 변경되었으나, Prometheus 설정에 인증 정보가 추가되지 않았습니다.",
    "solution": "1. Prometheus 설정에 basic_auth 추가\n2. /metrics 엔드포인트를 인증 제외 경로로 변경\n3. Prometheus 서비스 재시작\n4. 누락된 메트릭 데이터 복구 (불가능한 부분 있음)",
    "prevention": "1. 모니터링 엔드포인트는 항상 인증 제외\n2. Prometheus 연결 상태 알림 설정\n3. 메트릭 수집 gap 탐지 자동화\n4. Prometheus 설정 변경 시 사전 테스트",
    "tags": ["prometheus", "monitoring", "metrics"]
  },
  {
    "incident_id": "INC-2024-009",
    "title": "Docker Volume 디스크 공간 부족",
    "severity": "high",
    "category": "infrastructure",
    "occurred_at": "2024-02-25T15:00:00Z",
    "resolved_at": "2024-02-25T17:30:00Z",
    "affected_systems": ["Docker", "PostgreSQL", "Qdrant", "All Services"],
    "description": "Docker volume이 사용하는 디스크 공간이 100%에 도달하여 모든 서비스가 중단되었습니다.",
    "root_cause": "PostgreSQL 및 Qdrant의 데이터가 계속 증가했으나 디스크 용량 모니터링이 없었습니다. 특히 로그 파일이 로테이션되지 않고 누적되었습니다.",
    "solution": "1. 오래된 로그 파일 삭제 (30일 이상)\n2. PostgreSQL VACUUM FULL 실행\n3. Qdrant 불필요한 스냅샷 삭제\n4. 디스크 용량 80GB → 200GB로 증가\n5. 로그 로테이션 설정 (7일, 최대 1GB)\n6. 자동 정리 cron job 설정",
    "prevention": "1. 디스크 사용률 80% 이상 시 알림\n2. 자동 로그 로테이션 및 압축\n3. 데이터 보관 정책 수립 및 적용\n4. 주간 디스크 사용량 리포트",
    "tags": ["docker", "disk-space", "infrastructure"]
  },
  {
    "incident_id": "INC-2024-010",
    "title": "LLM Function Calling 파싱 오류",
    "severity": "medium",
    "category": "ai",
    "occurred_at": "2024-03-01T12:00:00Z",
    "resolved_at": "2024-03-01T13:30:00Z",
    "affected_systems": ["LLMService", "All Agents"],
    "description": "LLM이 반환한 Function Call 인자를 파싱하는 과정에서 JSON 파싱 오류가 발생했습니다.",
    "root_cause": "LLM이 가끔 잘못된 JSON 형식으로 인자를 반환했습니다. 특히 문자열 안에 escape되지 않은 따옴표가 포함되는 경우 문제가 발생했습니다.",
    "solution": "1. JSON 파싱 오류 시 재시도 로직 추가\n2. LLM에게 더 명확한 JSON 출력 지시 프롬프트 추가\n3. Relaxed JSON parser 도입 (json-repair 라이브러리)\n4. Function schema에 더 상세한 타입 및 예시 추가\n5. 파싱 실패 케이스 로깅 및 모니터링",
    "prevention": "1. Function calling 대신 structured output 사용 고려\n2. 정기적인 프롬프트 최적화\n3. LLM 버전 업그레이드 시 회귀 테스트\n4. 파싱 오류율 모니터링 (목표: <1%)",
    "tags": ["llm", "function-calling", "json", "parsing"]
  },
  {
    "incident_id": "INC-2024-011",
    "title": "Agent간 순환 의존성으로 인한 Deadlock",
    "severity": "high",
    "category": "orchestration",
    "occurred_at": "2024-03-05T09:30:00Z",
    "resolved_at": "2024-03-05T11:00:00Z",
    "affected_systems": ["Multi-Agent System", "ChangeManagementAgent", "MonitoringAgent"],
    "description": "ChangeManagementAgent와 MonitoringAgent가 서로를 호출하면서 무한 대기 상태에 빠져 작업이 완료되지 않았습니다.",
    "root_cause": "Agent 간 위임(delegation) 로직에서 순환 의존성 체크가 없었습니다. ChangeManagementAgent가 MonitoringAgent를 호출하고, MonitoringAgent가 다시 ChangeManagementAgent를 호출하는 상황이 발생했습니다.",
    "solution": "1. 영향받은 Task 수동 종료\n2. Agent 호출 체인 추적 로직 추가\n3. 순환 의존성 탐지 및 차단 로직 구현\n4. 최대 호출 깊이 제한 (max_depth=5)\n5. Timeout 메커니즘 강화",
    "prevention": "1. Agent 의존성 그래프 시각화 및 검토\n2. Agent 간 호출 규칙 명확히 정의\n3. 순환 호출 테스트 케이스 추가\n4. LangGraph 활용한 명시적 워크플로우 정의",
    "tags": ["multi-agent", "deadlock", "orchestration"]
  },
  {
    "incident_id": "INC-2024-012",
    "title": "Embedding 생성 속도 저하",
    "severity": "low",
    "category": "performance",
    "occurred_at": "2024-03-10T14:00:00Z",
    "resolved_at": "2024-03-10T16:00:00Z",
    "affected_systems": ["LLMService", "RAGService", "Knowledge Base Indexing"],
    "description": "문서 인덱싱 시 Embedding 생성 속도가 급격히 느려져 1000개 문서 인덱싱에 2시간 이상 소요되었습니다.",
    "root_cause": "Embedding API를 순차적으로 호출했고, 각 호출마다 네트워크 왕복 시간이 추가되었습니다. 배치 처리를 사용하지 않았습니다.",
    "solution": "1. Embedding API 배치 호출 구현 (한 번에 16개)\n2. 비동기 병렬 처리 도입 (asyncio.gather)\n3. 로컬 캐싱 추가 (동일 텍스트 재사용)\n4. 결과: 1000개 문서 인덱싱 시간 2시간 → 10분으로 단축",
    "prevention": "1. 항상 배치 API 사용\n2. 성능 테스트를 정기적으로 수행\n3. Embedding 생성 시간 모니터링\n4. 문서가 많은 경우 분산 처리 고려",
    "tags": ["embedding", "performance", "optimization"]
  }
]
